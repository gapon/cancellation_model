{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51761 train samples loaded\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.cross_validation import KFold, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from six.moves import cPickle as pickle\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "features = pd.read_csv('train/train_small.csv', header = 0)\n",
    "X = features.drop(['order_id','cancel', 'dow'], axis=1)\n",
    "y = features['cancel']\n",
    "print('{0} train samples loaded'.format(len(X)))\n",
    "\n",
    "#print(X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def fill_na_zero(df, col_name):\n",
    "#    df[col_name] = df[col_name].fillna(df[col_name].mean())\n",
    "#    df = df.fillna(0)\n",
    "#    #df = df.fillna(df.mean())\n",
    "#    return df\n",
    "\n",
    "def fill_na_mean(df, col_names):\n",
    "    for c in col_names:\n",
    "        df[c] = df[c].fillna(df[c].mean())\n",
    "    return df\n",
    "\n",
    "def le_fit_transform(df, col_name):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(df[col_name])\n",
    "    df[col_name] = le.transform(df[col_name])\n",
    "    return df, le\n",
    "\n",
    "def le_transform(df, col_name, le):\n",
    "    df[col_name] = le.transform(df[col_name])\n",
    "    return df\n",
    "\n",
    "def ohc_fit_transform(df, col_name):\n",
    "    ohe = OneHotEncoder(sparse=False)\n",
    "    ohe.fit(df[col_name].values.reshape(-1, 1))\n",
    "    encoded_col = ohe.transform(df[col_name].values.reshape(-1, 1))\n",
    "    #encoded_col = ohe.fit_transform(df[col_name].values.reshape(-1, 1))\n",
    "    tmp = pd.DataFrame(encoded_col, columns=[col_name + str(i) for i in range(encoded_col.shape[1])], index = df.index)\n",
    "    df = pd.concat([df, tmp], axis = 1)\n",
    "    df = df.drop([col_name], axis = 1)\n",
    "    return df, ohe\n",
    "\n",
    "def ohc_transform(df, col_name, ohe):\n",
    "    encoded_col = ohe.transform(df[col_name].values.reshape(-1, 1))\n",
    "    tmp = pd.DataFrame(encoded_col, columns=[col_name + str(i) for i in range(encoded_col.shape[1])], index = df.index)\n",
    "    df = pd.concat([df, tmp], axis = 1)\n",
    "    df = df.drop([col_name], axis = 1)\n",
    "    return df\n",
    "\n",
    "def exponentiation(df, cols):\n",
    "    for c in cols:\n",
    "        df[c + '_sq'] = df[c]**2\n",
    "        df[c + '_sqrt'] = np.sqrt(df[c])\n",
    "    return df\n",
    "        \n",
    "\n",
    " \n",
    "X = fill_na_mean(X, ['shifts_num', 'dow_paid_share'])\n",
    "X = X.fillna(-999)\n",
    "\n",
    "\n",
    "#X, le_type = le_fit_transform(X, 'type')\n",
    "#X, ohc_type = ohc_fit_transform(X, 'type')\n",
    "\n",
    "#X, le_start_hour = le_fit_transform(X, 'start_hour')\n",
    "#X, ohc_le_start_hour = ohc_fit_transform(X, 'start_hour')\n",
    "\n",
    "#X, le_creation_mean = le_fit_transform(X, 'creation_mean')\n",
    "#X, ohc_creation_mean = ohc_fit_transform(X, 'creation_mean')\n",
    "\n",
    "#X, le_payment_type = le_fit_transform(X, 'payment_type')\n",
    "#X, ohc_payment_type = ohc_fit_transform(X, 'payment_type')\n",
    "\n",
    "# X = exponentiation(X, ['paid_all','canceled_all_nt','paid_16d', 'paid_30d', 'paid_60d', 'canceled_16d_nt','canceled_30d_nt', 'canceled_60d_nt', 'dow_paid', 'dow_canceled'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient boosting fitting:\n",
      "Trees 70, Depth 5, Learning Rate 0.2, Time to fit: 0:00:45.554352, ROC-AUC: 0.8179327555810222\n"
     ]
    }
   ],
   "source": [
    "folds = 5\n",
    "kf = KFold(len(X), folds, shuffle=True, random_state=42)\n",
    "trees = [70]\n",
    "depths = [5]\n",
    "rates = [0.2]\n",
    "\n",
    "\n",
    "print()\n",
    "print('Gradient boosting fitting:')\n",
    "\n",
    "for t in trees:\n",
    "    for d in depths:\n",
    "        for r in rates:\n",
    "            start_time = datetime.datetime.now()\n",
    "            gb_clf = GradientBoostingClassifier(learning_rate=r, n_estimators=t, verbose=False, random_state=241, max_depth = d)\n",
    "            scores = cross_val_score(gb_clf, X=X, y=y, scoring='roc_auc', cv=kf)\n",
    "            time_to_fit = datetime.datetime.now() - start_time\n",
    "            print('Trees {0}, Depth {1}, Learning Rate {2}, Time to fit: {3}, ROC-AUC: {4}'.format(t, d, r, time_to_fit, scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             features  importance\n",
      "8                        day_slot_flg    0.003126\n",
      "18                           paid_30d    0.005329\n",
      "20                    canceled_16d_nt    0.007866\n",
      "17                           paid_16d    0.008632\n",
      "24                canceled_onetime_nt    0.008717\n",
      "21                    canceled_30d_nt    0.009406\n",
      "5                            auto_flg    0.011036\n",
      "22                    canceled_60d_nt    0.011335\n",
      "28                           dow_paid    0.013100\n",
      "9                         has_comment    0.014610\n",
      "4                            cash_flg    0.015636\n",
      "6                                 hot    0.016942\n",
      "10                   subscription_flg    0.017871\n",
      "15                    canceled_all_nt    0.017951\n",
      "26  days_since_last_cancel_onetime_nt    0.020094\n",
      "29                       dow_canceled    0.020151\n",
      "3                        discount_prc    0.023600\n",
      "31                 dow_all_paid_share    0.028232\n",
      "19                           paid_60d    0.028624\n",
      "2                            discount    0.028893\n",
      "7                     additionals_num    0.030746\n",
      "1                      subtotal_cents    0.034598\n",
      "0                         total_cents    0.036935\n",
      "25      days_since_last_cancel_all_nt    0.037691\n",
      "14                           paid_all    0.043355\n",
      "23                         shifts_num    0.049124\n",
      "16              canceled_all_nt_share    0.055512\n",
      "12                                lng    0.064198\n",
      "30                     dow_paid_share    0.065798\n",
      "11                                lat    0.067520\n",
      "27         days_since_last_paid_order    0.074583\n",
      "13               creation_start_hours    0.128791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gapon/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:8: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "final_gb_clf = GradientBoostingClassifier(learning_rate=0.2, n_estimators=70, max_depth=5, verbose=False, random_state=241)\n",
    "final_gb_clf.fit(X, y)\n",
    "\n",
    "\n",
    "coeff = final_gb_clf.feature_importances_\n",
    "names = X.columns.values\n",
    "df = pd.DataFrame({'features':names, 'importance':coeff})\n",
    "print(df.sort('importance'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['admin', 'auto', 'crm', 'ios', 'reactivation', 'web_new_flow'], dtype=object)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le_creation_mean.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dump model to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#file_name = 'cancellations_model.pickle'\n",
    "#with open(file_name, 'wb') as f:\n",
    "#    pickle.dump(final_gb_clf, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_file = 'cancellations_model.pickle'\n",
    "try:\n",
    "    f = open(pickle_file, 'wb')\n",
    "    save = {\n",
    "        'model': final_gb_clf,\n",
    "        #'ohc_dow': ohc_dow,\n",
    "        #'le_type': le_type,\n",
    "        #'ohc_type': ohc_type,\n",
    "        #'le_creation_mean': le_creation_mean,\n",
    "        #'ohc_creation_mean': ohc_creation_mean,\n",
    "        #'le_payment_type': le_payment_type,\n",
    "        #'ohc_payment_type': ohc_payment_type,\n",
    "    }\n",
    "    pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "    f.close()\n",
    "except Exception as e:\n",
    "    print('Unable to save data to', pickle_file, ':', e)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тест на отложенной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.826187226577\n"
     ]
    }
   ],
   "source": [
    "features = pd.read_csv('test/test-20-29-jun.csv', header = 0)\n",
    "\n",
    "X_test = features.drop(['order_id','cancel', 'dow'], axis=1)\n",
    "\n",
    "\n",
    "# X_test = fill_na(X_test, 'shifts_num')\n",
    "\n",
    "X_test = fill_na_mean(X_test, ['shifts_num', 'dow_paid_share'])\n",
    "\n",
    "X_test = X_test.fillna(-999)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#X_test = ohc_transform(X_test, 'dow', ohc_dow)\n",
    "\n",
    "#X_test = le_transform(X_test, 'type', le_type)\n",
    "#X_test = ohc_transform(X_test, 'type', ohc_type)\n",
    "\n",
    "#X_test = le_transform(X_test, 'creation_mean', le_creation_mean)\n",
    "#X_test = ohc_transform(X_test, 'creation_mean', ohc_creation_mean)\n",
    "\n",
    "#X_test = le_transform(X_test, 'payment_type', le_payment_type)\n",
    "#X_test = ohc_transform(X_test, 'payment_type', ohc_payment_type)\n",
    "\n",
    "# X_test = exponentiation(\n",
    "#    X_test, ['paid_all','canceled_all','paid_16d','canceled_16d', 'paid_30d','canceled_30d', 'paid_60d','canceled_60d'])\n",
    "\n",
    "\n",
    "y_true = features['cancel']\n",
    "y_pred = final_gb_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "print(roc_auc_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bins = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "group_names = ['0-10', '10-20', '20-30', '30-40', '40-50', '50-60', '60-70', '70-80', '80-90', '90-100']\n",
    "\n",
    "categories = pd.cut(y_pred, bins, labels=group_names)\n",
    "\n",
    "df = pd.DataFrame(columns=['y_true', 'y_pred', 'bin'])\n",
    "df['y_true'] = y_true\n",
    "df['y_pred'] = y_pred\n",
    "df['bin'] = categories\n",
    "\n",
    "df.to_csv('bins_nt_model-2017-06-29.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.47702018  0.50489465  0.47570555 ...,  0.5580376   0.10706268\n",
      "  0.17947012]\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "features = pd.read_csv('predict/2017-07-01.csv', header = 0, index_col='order_id')\n",
    "#X_test = read_csv('test/test-2017.csv', index_col=[0,1,2,3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Preprocessing\n",
    "X_test = features\n",
    "\n",
    "X_test = features.drop(['dow'], axis=1)\n",
    "X_test = fill_na_mean(X_test, ['shifts_num', 'dow_paid_share'])\n",
    "X_test = X_test.fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "#y_true = features['cancel']\n",
    "y_pred = final_gb_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "#print(roc_auc_score(y_true, y_pred))\n",
    "print(y_pred)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(index=X_test.index, columns=['will_cancel'])\n",
    "df['will_cancel'] = final_gb_clf.predict_proba(X_test)[:,1]\n",
    "df.to_csv('predict/predict-2017-07-01.csv')\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
