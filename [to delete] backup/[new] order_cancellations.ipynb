{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374200 train samples loaded\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.cross_validation import KFold, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "features = pd.read_csv('train/train_big.csv', header = 0)\n",
    "X = features.drop(['order_id','cancel'], axis=1)\n",
    "y = features['cancel']\n",
    "print('{0} train samples loaded'.format(len(X)))\n",
    "\n",
    "#print(X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_na(df, col_name):\n",
    "    df[col_name] = df[col_name].fillna(df[col_name].mean())\n",
    "    df = df.fillna(0)\n",
    "    return df\n",
    "\n",
    "def le_fit_transform(df, col_name):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(df[col_name])\n",
    "    df[col_name] = le.transform(df[col_name])\n",
    "    return df, le\n",
    "\n",
    "def le_transform(df, col_name, le):\n",
    "    df[col_name] = le.transform(df[col_name])\n",
    "    return df\n",
    "\n",
    "def ohc_fit_transform(df, col_name):\n",
    "    ohe = OneHotEncoder(sparse=False)\n",
    "    ohe.fit(df[col_name].values.reshape(-1, 1))\n",
    "    encoded_col = ohe.transform(df[col_name].values.reshape(-1, 1))\n",
    "    #encoded_col = ohe.fit_transform(df[col_name].values.reshape(-1, 1))\n",
    "    tmp = pd.DataFrame(encoded_col, columns=[col_name + str(i) for i in range(encoded_col.shape[1])], index = df.index)\n",
    "    df = pd.concat([df, tmp], axis = 1)\n",
    "    df = df.drop([col_name], axis = 1)\n",
    "    return df, ohe\n",
    "\n",
    "def ohc_transform(df, col_name, ohe):\n",
    "    encoded_col = ohe.transform(df[col_name].values.reshape(-1, 1))\n",
    "    tmp = pd.DataFrame(encoded_col, columns=[col_name + str(i) for i in range(encoded_col.shape[1])], index = df.index)\n",
    "    df = pd.concat([df, tmp], axis = 1)\n",
    "    df = df.drop([col_name], axis = 1)\n",
    "    return df\n",
    "\n",
    "def exponentiation(df, cols):\n",
    "    for c in cols:\n",
    "        df[c + '_sq'] = df[c]**2\n",
    "        df[c + '_sqrt'] = np.sqrt(df[c])\n",
    "    return df\n",
    "        \n",
    "\n",
    " \n",
    "X = fill_na(X, 'shifts_num')\n",
    "\n",
    "X, ohc_dow = ohc_fit_transform(X, 'dow')\n",
    "\n",
    "X, le_type = le_fit_transform(X, 'type')\n",
    "X, ohc_type = ohc_fit_transform(X, 'type')\n",
    "\n",
    "X, le_creation_mean = le_fit_transform(X, 'creation_mean')\n",
    "X, ohc_creation_mean = ohc_fit_transform(X, 'creation_mean')\n",
    "\n",
    "X, le_payment_type = le_fit_transform(X, 'payment_type')\n",
    "X, ohc_payment_type = ohc_fit_transform(X, 'payment_type')\n",
    "\n",
    "X = exponentiation(X, ['paid_all','canceled_all','paid_16d','canceled_16d', 'paid_30d','canceled_30d', 'paid_60d','canceled_60d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient boosting fitting:\n",
      "Trees 10, Depth 3, Learning Rate 0.2, Time to fit: 0:01:39.963544, ROC-AUC: 0.860007446230256\n",
      "Trees 10, Depth 4, Learning Rate 0.2, Time to fit: 0:02:22.858603, ROC-AUC: 0.8800338839699634\n",
      "Trees 50, Depth 3, Learning Rate 0.2, Time to fit: 0:06:03.632265, ROC-AUC: 0.9032229368724007\n",
      "Trees 50, Depth 4, Learning Rate 0.2, Time to fit: 0:10:04.550437, ROC-AUC: 0.9093175906363371\n",
      "Trees 100, Depth 3, Learning Rate 0.2, Time to fit: 0:12:39.006230, ROC-AUC: 0.9085114273831738\n",
      "Trees 100, Depth 4, Learning Rate 0.2, Time to fit: 0:18:38.343109, ROC-AUC: 0.912996632246162\n"
     ]
    }
   ],
   "source": [
    "folds = 5\n",
    "kf = KFold(len(X), folds, shuffle=True, random_state=42)\n",
    "trees = [10, 50, 100]\n",
    "depths = [3, 4]\n",
    "rates = [0.2]\n",
    "\n",
    "\n",
    "print()\n",
    "print('Gradient boosting fitting:')\n",
    "\n",
    "for t in trees:\n",
    "    for d in depths:\n",
    "        for r in rates:\n",
    "            start_time = datetime.datetime.now()\n",
    "            gb_clf = GradientBoostingClassifier(learning_rate=r, n_estimators=t, verbose=False, random_state=241, max_depth = d)\n",
    "            scores = cross_val_score(gb_clf, X=X, y=y, scoring='roc_auc', cv=kf)\n",
    "            time_to_fit = datetime.datetime.now() - start_time\n",
    "            print('Trees {0}, Depth {1}, Learning Rate {2}, Time to fit: {3}, ROC-AUC: {4}'.format(t, d, r, time_to_fit, scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                features  importance\n",
      "17            shower_flg    0.000000\n",
      "53                 type2    0.000000\n",
      "58        creation_mean4    0.000000\n",
      "19               cat_flg    0.000000\n",
      "61        creation_mean7    0.000000\n",
      "21          wardrobe_flg    0.000000\n",
      "47                  dow3    0.000000\n",
      "77     canceled_30d_sqrt    0.000000\n",
      "11  kitchen_cabinets_flg    0.000130\n",
      "52                 type1    0.000172\n",
      "46                  dow2    0.000352\n",
      "25          evening_slot    0.000360\n",
      "49                  dow5    0.000572\n",
      "38          canceled_30d    0.000576\n",
      "72       canceled_16d_sq    0.000576\n",
      "20            lustre_flg    0.000717\n",
      "13         balconies_flg    0.000798\n",
      "81     canceled_60d_sqrt    0.000829\n",
      "10           ironing_flg    0.000829\n",
      "48                  dow4    0.000837\n",
      "45                  dow1    0.000860\n",
      "18          bedlinen_flg    0.001089\n",
      "62        creation_mean8    0.001102\n",
      "16       consumables_flg    0.001163\n",
      "35          canceled_16d    0.001164\n",
      "44                  dow0    0.001390\n",
      "51                 type0    0.001614\n",
      "59        creation_mean5    0.001708\n",
      "50                  dow6    0.001906\n",
      "24              day_slot    0.002023\n",
      "..                   ...         ...\n",
      "79         paid_60d_sqrt    0.008136\n",
      "68       canceled_all_sq    0.009273\n",
      "26           has_comment    0.009340\n",
      "63         payment_type0    0.009562\n",
      "40              paid_60d    0.011125\n",
      "39    canceled_30d_share    0.011293\n",
      "67         paid_all_sqrt    0.011536\n",
      "78           paid_60d_sq    0.011929\n",
      "54        creation_mean0    0.012359\n",
      "3         subtotal_cents    0.012958\n",
      "36    canceled_16d_share    0.013324\n",
      "71         paid_16d_sqrt    0.013988\n",
      "2            total_cents    0.014489\n",
      "34              paid_16d    0.014849\n",
      "60        creation_mean6    0.015432\n",
      "31              paid_all    0.015466\n",
      "22       additionals_num    0.016963\n",
      "27      subscription_flg    0.019142\n",
      "66           paid_all_sq    0.019144\n",
      "6                    hot    0.019189\n",
      "28                   lat    0.023486\n",
      "70           paid_16d_sq    0.023686\n",
      "4               discount    0.026263\n",
      "29                   lng    0.030627\n",
      "55        creation_mean1    0.030811\n",
      "42    canceled_60d_share    0.056001\n",
      "43            shifts_num    0.062002\n",
      "33    canceled_all_share    0.062872\n",
      "30  creation_start_hours    0.137046\n",
      "5           discount_prc    0.166034\n",
      "\n",
      "[82 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gapon/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:8: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "final_gb_clf = GradientBoostingClassifier(learning_rate=0.2, n_estimators=100, verbose=False, random_state=241, max_depth=4)\n",
    "final_gb_clf.fit(X, y)\n",
    "\n",
    "\n",
    "coeff = final_gb_clf.feature_importances_\n",
    "names = X.columns.values\n",
    "df = pd.DataFrame({'features':names, 'importance':coeff})\n",
    "print(df.sort('importance'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тест на отложенной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.853840089084\n"
     ]
    }
   ],
   "source": [
    "features = pd.read_csv('test/test-new-16-19-may.csv', header = 0)\n",
    "\n",
    "X_test = features.drop(['order_id','cancel'], axis=1)\n",
    "\n",
    "\n",
    "X_test = fill_na(X_test, 'shifts_num')\n",
    "\n",
    "X_test = ohc_transform(X_test, 'dow', ohc_dow)\n",
    "\n",
    "X_test = le_transform(X_test, 'type', le_type)\n",
    "X_test = ohc_transform(X_test, 'type', ohc_type)\n",
    "\n",
    "X_test = le_transform(X_test, 'creation_mean', le_creation_mean)\n",
    "X_test = ohc_transform(X_test, 'creation_mean', ohc_creation_mean)\n",
    "\n",
    "X_test = le_transform(X_test, 'payment_type', le_payment_type)\n",
    "X_test = ohc_transform(X_test, 'payment_type', ohc_payment_type)\n",
    "\n",
    "X_test = exponentiation(\n",
    "    X_test, ['paid_all','canceled_all','paid_16d','canceled_16d', 'paid_30d','canceled_30d', 'paid_60d','canceled_60d'])\n",
    "\n",
    "\n",
    "y_true = features['cancel']\n",
    "y_pred = final_gb_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "print(roc_auc_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bins = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "group_names = ['0-10', '10-20', '20-30', '30-40', '40-50', '50-60', '60-70', '70-80', '80-90', '90-100']\n",
    "\n",
    "categories = pd.cut(y_pred, bins, labels=group_names)\n",
    "\n",
    "df = pd.DataFrame(columns=['y_true', 'y_pred', 'bin'])\n",
    "df['y_true'] = y_true\n",
    "df['y_pred'] = y_pred\n",
    "df['bin'] = categories\n",
    "\n",
    "df.to_csv('bins_new_model.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output in YYYY-MM-DD.csv\n"
     ]
    }
   ],
   "source": [
    "X_test = read_csv('test/test-2017.csv', index_col=[0,1,2,3])\n",
    "\n",
    "df = DataFrame(index=X_test.index, columns=['will_cancel'])\n",
    "df['will_cancel'] = final_gb_clf.predict_proba(X_test)[:,1]\n",
    "# df.to_csv('predictions/prediction-2017-04-07-2.csv')\n",
    "print('Output in YYYY-MM-DD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gapon/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_work = df[df['will_cancel']>=0.5]\n",
    "bins = [0.5, 0.65, 0.80, 1.0]\n",
    "group_names = ['green', 'yellow', 'red']\n",
    "\n",
    "categories = pd.cut(df_work['will_cancel'], bins, labels=group_names)\n",
    "df_work['categories'] = pd.cut(df_work['will_cancel'], bins, labels=group_names)\n",
    "\n",
    "df_work.to_csv('predictions/prediction-2017-05-02.csv')\n",
    "print(len(df_work))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
