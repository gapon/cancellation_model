{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374200 train samples loaded\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.cross_validation import KFold, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "features = pd.read_csv('train/train_nt.csv', header = 0)\n",
    "X = features.drop(['order_id','cancel'], axis=1)\n",
    "y = features['cancel']\n",
    "print('{0} train samples loaded'.format(len(X)))\n",
    "\n",
    "#print(X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_na(df, col_name):\n",
    "    df[col_name] = df[col_name].fillna(df[col_name].mean())\n",
    "    df = df.fillna(0)\n",
    "    return df\n",
    "\n",
    "def le_fit_transform(df, col_name):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(df[col_name])\n",
    "    df[col_name] = le.transform(df[col_name])\n",
    "    return df, le\n",
    "\n",
    "def le_transform(df, col_name, le):\n",
    "    df[col_name] = le.transform(df[col_name])\n",
    "    return df\n",
    "\n",
    "def ohc_fit_transform(df, col_name):\n",
    "    ohe = OneHotEncoder(sparse=False)\n",
    "    ohe.fit(df[col_name].values.reshape(-1, 1))\n",
    "    encoded_col = ohe.transform(df[col_name].values.reshape(-1, 1))\n",
    "    #encoded_col = ohe.fit_transform(df[col_name].values.reshape(-1, 1))\n",
    "    tmp = pd.DataFrame(encoded_col, columns=[col_name + str(i) for i in range(encoded_col.shape[1])], index = df.index)\n",
    "    df = pd.concat([df, tmp], axis = 1)\n",
    "    df = df.drop([col_name], axis = 1)\n",
    "    return df, ohe\n",
    "\n",
    "def ohc_transform(df, col_name, ohe):\n",
    "    encoded_col = ohe.transform(df[col_name].values.reshape(-1, 1))\n",
    "    tmp = pd.DataFrame(encoded_col, columns=[col_name + str(i) for i in range(encoded_col.shape[1])], index = df.index)\n",
    "    df = pd.concat([df, tmp], axis = 1)\n",
    "    df = df.drop([col_name], axis = 1)\n",
    "    return df\n",
    "\n",
    "def exponentiation(df, cols):\n",
    "    for c in cols:\n",
    "        df[c + '_sq'] = df[c]**2\n",
    "        df[c + '_sqrt'] = np.sqrt(df[c])\n",
    "    return df\n",
    "        \n",
    "\n",
    " \n",
    "X = fill_na(X, 'shifts_num')\n",
    "\n",
    "X, ohc_dow = ohc_fit_transform(X, 'dow')\n",
    "\n",
    "X, le_type = le_fit_transform(X, 'type')\n",
    "X, ohc_type = ohc_fit_transform(X, 'type')\n",
    "\n",
    "X, le_creation_mean = le_fit_transform(X, 'creation_mean')\n",
    "X, ohc_creation_mean = ohc_fit_transform(X, 'creation_mean')\n",
    "\n",
    "X, le_payment_type = le_fit_transform(X, 'payment_type')\n",
    "X, ohc_payment_type = ohc_fit_transform(X, 'payment_type')\n",
    "\n",
    "#X = exponentiation(X, ['paid_all','canceled_all_nt','paid_16d','canceled_16d', 'paid_30d','canceled_30d', 'paid_60d','canceled_60d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient boosting fitting:\n",
      "Trees 10, Depth 3, Learning Rate 0.2, Time to fit: 0:01:07.304045, ROC-AUC: 0.9213524173423059\n",
      "Trees 10, Depth 4, Learning Rate 0.2, Time to fit: 0:01:46.830837, ROC-AUC: 0.938006081813136\n",
      "Trees 50, Depth 3, Learning Rate 0.2, Time to fit: 0:04:30.060664, ROC-AUC: 0.9540729007829573\n",
      "Trees 50, Depth 4, Learning Rate 0.2, Time to fit: 0:06:54.183669, ROC-AUC: 0.9586141044354536\n",
      "Trees 100, Depth 3, Learning Rate 0.2, Time to fit: 0:08:30.963746, ROC-AUC: 0.9585022203092922\n",
      "Trees 100, Depth 4, Learning Rate 0.2, Time to fit: 0:14:01.517576, ROC-AUC: 0.9612823454684618\n"
     ]
    }
   ],
   "source": [
    "folds = 5\n",
    "kf = KFold(len(X), folds, shuffle=True, random_state=42)\n",
    "trees = [10, 50]\n",
    "depths = [3, 4]\n",
    "rates = [0.2]\n",
    "\n",
    "\n",
    "print()\n",
    "print('Gradient boosting fitting:')\n",
    "\n",
    "for t in trees:\n",
    "    for d in depths:\n",
    "        for r in rates:\n",
    "            start_time = datetime.datetime.now()\n",
    "            gb_clf = GradientBoostingClassifier(learning_rate=r, n_estimators=t, verbose=False, random_state=241, max_depth = d)\n",
    "            scores = cross_val_score(gb_clf, X=X, y=y, scoring='roc_auc', cv=kf)\n",
    "            time_to_fit = datetime.datetime.now() - start_time\n",
    "            print('Trees {0}, Depth {1}, Learning Rate {2}, Time to fit: {3}, ROC-AUC: {4}'.format(t, d, r, time_to_fit, scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                features    importance\n",
      "20                          bedlinen_flg  0.000000e+00\n",
      "45         days_since_last_cancel_ivr_nt  0.000000e+00\n",
      "46      days_since_last_cancel_subscr_nt  0.000000e+00\n",
      "48  days_since_last_cancel_partsubscr_nt  0.000000e+00\n",
      "54                                  dow5  0.000000e+00\n",
      "23                          wardrobe_flg  0.000000e+00\n",
      "40                       canceled_ivr_nt  0.000000e+00\n",
      "19                            shower_flg  0.000000e+00\n",
      "41                    canceled_subscr_nt  0.000000e+00\n",
      "66                        creation_mean8  0.000000e+00\n",
      "65                        creation_mean7  0.000000e+00\n",
      "7                                   pets  0.000000e+00\n",
      "47     days_since_last_cancel_onetime_nt  4.712928e-07\n",
      "42                   canceled_onetime_nt  7.856131e-05\n",
      "14                         tableware_flg  1.442567e-04\n",
      "51                                  dow2  1.724086e-04\n",
      "43                canceled_partsubscr_nt  2.962857e-04\n",
      "27                          evening_slot  3.899916e-04\n",
      "21                               cat_flg  4.233996e-04\n",
      "50                                  dow1  5.576965e-04\n",
      "9                       refrigerator_flg  6.638771e-04\n",
      "52                                  dow3  7.537423e-04\n",
      "53                                  dow4  8.590663e-04\n",
      "62                        creation_mean4  1.224965e-03\n",
      "26                              day_slot  1.392746e-03\n",
      "13                  kitchen_cabinets_flg  1.451688e-03\n",
      "12                           ironing_flg  1.572313e-03\n",
      "63                        creation_mean5  1.595861e-03\n",
      "10                              oven_flg  1.602326e-03\n",
      "15                         balconies_flg  1.605397e-03\n",
      "..                                   ...           ...\n",
      "68                         payment_type1  4.054056e-03\n",
      "17                     keys_delivery_flg  4.208926e-03\n",
      "0                                  rooms  5.392706e-03\n",
      "61                        creation_mean3  6.181228e-03\n",
      "11                           windows_fls  6.183143e-03\n",
      "1                              bathrooms  6.361989e-03\n",
      "25                          morning_slot  6.470296e-03\n",
      "67                         payment_type0  6.679359e-03\n",
      "8                    need_vacuum_cleaner  8.149404e-03\n",
      "58                        creation_mean0  1.054552e-02\n",
      "2                            total_cents  1.109355e-02\n",
      "64                        creation_mean6  1.623673e-02\n",
      "28                           has_comment  1.707035e-02\n",
      "6                                    hot  1.712984e-02\n",
      "3                         subtotal_cents  1.895528e-02\n",
      "24                       additionals_num  2.178574e-02\n",
      "30                                   lat  2.190150e-02\n",
      "59                        creation_mean1  2.251293e-02\n",
      "37                              paid_30d  2.311890e-02\n",
      "29                      subscription_flg  2.620500e-02\n",
      "4                               discount  2.658781e-02\n",
      "31                                   lng  4.505139e-02\n",
      "33                              paid_all  5.247750e-02\n",
      "39                            shifts_num  5.555573e-02\n",
      "35                 canceled_all_nt_share  5.789588e-02\n",
      "34                       canceled_all_nt  5.982917e-02\n",
      "38                              paid_60d  6.299670e-02\n",
      "36                              paid_16d  7.133483e-02\n",
      "32                  creation_start_hours  1.280078e-01\n",
      "5                           discount_prc  1.397729e-01\n",
      "\n",
      "[70 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gapon/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:8: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "final_gb_clf = GradientBoostingClassifier(learning_rate=0.2, n_estimators=100, verbose=False, random_state=241, max_depth=4)\n",
    "final_gb_clf.fit(X, y)\n",
    "\n",
    "\n",
    "coeff = final_gb_clf.feature_importances_\n",
    "names = X.columns.values\n",
    "df = pd.DataFrame({'features':names, 'importance':coeff})\n",
    "print(df.sort('importance'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тест на отложенной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.912137450523\n"
     ]
    }
   ],
   "source": [
    "features = pd.read_csv('test/test-nt-01-20-jun.csv', header = 0)\n",
    "\n",
    "X_test = features.drop(['order_id','cancel'], axis=1)\n",
    "\n",
    "\n",
    "X_test = fill_na(X_test, 'shifts_num')\n",
    "\n",
    "X_test = ohc_transform(X_test, 'dow', ohc_dow)\n",
    "\n",
    "X_test = le_transform(X_test, 'type', le_type)\n",
    "X_test = ohc_transform(X_test, 'type', ohc_type)\n",
    "\n",
    "X_test = le_transform(X_test, 'creation_mean', le_creation_mean)\n",
    "X_test = ohc_transform(X_test, 'creation_mean', ohc_creation_mean)\n",
    "\n",
    "X_test = le_transform(X_test, 'payment_type', le_payment_type)\n",
    "X_test = ohc_transform(X_test, 'payment_type', ohc_payment_type)\n",
    "\n",
    "# X_test = exponentiation(\n",
    "#    X_test, ['paid_all','canceled_all','paid_16d','canceled_16d', 'paid_30d','canceled_30d', 'paid_60d','canceled_60d'])\n",
    "\n",
    "\n",
    "y_true = features['cancel']\n",
    "y_pred = final_gb_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "print(roc_auc_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bins = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "group_names = ['0-10', '10-20', '20-30', '30-40', '40-50', '50-60', '60-70', '70-80', '80-90', '90-100']\n",
    "\n",
    "categories = pd.cut(y_pred, bins, labels=group_names)\n",
    "\n",
    "df = pd.DataFrame(columns=['y_true', 'y_pred', 'bin'])\n",
    "df['y_true'] = y_true\n",
    "df['y_pred'] = y_pred\n",
    "df['bin'] = categories\n",
    "\n",
    "df.to_csv('bins_nt_model.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output in YYYY-MM-DD.csv\n"
     ]
    }
   ],
   "source": [
    "X_test = read_csv('test/test-2017.csv', index_col=[0,1,2,3])\n",
    "\n",
    "df = DataFrame(index=X_test.index, columns=['will_cancel'])\n",
    "df['will_cancel'] = final_gb_clf.predict_proba(X_test)[:,1]\n",
    "# df.to_csv('predictions/prediction-2017-04-07-2.csv')\n",
    "print('Output in YYYY-MM-DD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gapon/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_work = df[df['will_cancel']>=0.5]\n",
    "bins = [0.5, 0.65, 0.80, 1.0]\n",
    "group_names = ['green', 'yellow', 'red']\n",
    "\n",
    "categories = pd.cut(df_work['will_cancel'], bins, labels=group_names)\n",
    "df_work['categories'] = pd.cut(df_work['will_cancel'], bins, labels=group_names)\n",
    "\n",
    "df_work.to_csv('predictions/prediction-2017-05-02.csv')\n",
    "print(len(df_work))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
